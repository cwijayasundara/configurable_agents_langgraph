"""
Simple Template Generator for Supervisor + Workers Hierarchical Teams
Generates optimized configurations for the simplified hierarchical model
"""
from typing import Dict, Any, List, Optional
from datetime import datetime
import yaml
from pathlib import Path


class SimpleTemplateGenerator:
    """Generates hierarchical configurations for supervisor + workers teams."""
    
    def __init__(self, agent_library):
        self.agent_library = agent_library
        
    def generate_simple_hierarchical_config(self, 
                                           team_name: str,
                                           team_description: str,
                                           supervisor_id: str,
                                           worker_ids: List[str]) -> str:
        """Generate a simplified hierarchical configuration YAML."""
        
        # Get agent metadata
        supervisor_metadata = self.agent_library.agents.get(supervisor_id)
        if not supervisor_metadata:
            raise ValueError(f"Supervisor '{supervisor_id}' not found")
        
        # Validate workers exist
        for worker_id in worker_ids:
            if worker_id not in self.agent_library.agents:
                raise ValueError(f"Worker '{worker_id}' not found")
        
        # Build configuration structure
        config = {
            "# Simple Hierarchical Team Configuration": None,
            "# Generated by Simple Team Builder": None,
            
            "team": {
                "name": team_name,
                "description": team_description,
                "type": "simple_hierarchical",
                "version": "1.0.0",
                "created": datetime.now().isoformat(),
                "generator": "simple_template_generator"
            },
            
            "architecture": {
                "pattern": "supervisor_workers",
                "description": "One supervisor coordinates multiple worker agents",
                "supervisor_count": 1,
                "worker_count": len(worker_ids),
                "total_agents": len(worker_ids) + 1
            },
            
            "supervisor": self._generate_supervisor_config(supervisor_id),
            "workers": self._generate_workers_config(worker_ids),
            "coordination": self._generate_coordination_config(),
            "runtime": self._generate_runtime_config(),
            "deployment": self._generate_deployment_config(team_name)
        }
        
        # Convert to YAML string
        yaml_str = yaml.dump(config, default_flow_style=False, indent=2, sort_keys=False)
        
        # Clean up None values (comments)
        lines = yaml_str.split('\n')
        cleaned_lines = [line for line in lines if not line.strip().endswith(': null')]
        
        return '\n'.join(cleaned_lines)
    
    def _generate_supervisor_config(self, supervisor_id: str) -> Dict[str, Any]:
        """Generate supervisor configuration."""
        supervisor_metadata = self.agent_library.agents[supervisor_id]
        
        # Get LLM config from supervisor's config file
        llm_config = self._extract_llm_config(supervisor_metadata.file_path)
        
        return {
            "name": supervisor_metadata.name,
            "description": supervisor_metadata.description,
            "agent_id": supervisor_id,
            "config_file": supervisor_metadata.file_path,
            "role": "supervisor",
            
            "capabilities": [cap.value for cap in supervisor_metadata.capabilities],
            "tools": supervisor_metadata.tools,
            
            "llm": llm_config,
            
            "prompts": {
                "system_prompt": {
                    "template": self._generate_supervisor_prompt_template(supervisor_metadata),
                    "variables": ["user_input", "worker_capabilities", "task_context", "memory_context"]
                },
                "routing_prompt": {
                    "template": self._generate_routing_prompt_template(),
                    "variables": ["user_request", "available_workers", "worker_specializations"]
                }
            },
            
            "routing": {
                "strategy": "capability_based",
                "fallback_strategy": "round_robin",
                "decision_threshold": 0.7,
                "max_retries": 2
            },
            
            "memory": {
                "enabled": True,
                "provider": "langmem",
                "types": {
                    "episodic": True,
                    "semantic": True,
                    "procedural": True
                },
                "retention_days": 30
            }
        }
    
    def _generate_workers_config(self, worker_ids: List[str]) -> List[Dict[str, Any]]:
        """Generate workers configuration."""
        workers_config = []
        
        for worker_id in worker_ids:
            worker_metadata = self.agent_library.agents[worker_id]
            
            worker_config = {
                "name": worker_metadata.name,
                "description": worker_metadata.description,
                "agent_id": worker_id,
                "config_file": worker_metadata.file_path,
                "role": "worker",
                
                "capabilities": [cap.value for cap in worker_metadata.capabilities],
                "tools": worker_metadata.tools,
                "specializations": worker_metadata.specializations,
                
                "llm": self._extract_llm_config(worker_metadata.file_path),
                
                "performance": {
                    "timeout_seconds": 120,
                    "retry_attempts": 2,
                    "priority": 1,
                    "max_concurrent_tasks": 1
                },
                
                "memory": {
                    "enabled": True,
                    "provider": "langmem",
                    "types": {
                        "episodic": True,
                        "semantic": True
                    },
                    "retention_days": 15
                }
            }
            
            workers_config.append(worker_config)
        
        return workers_config
    
    def _generate_coordination_config(self) -> Dict[str, Any]:
        """Generate coordination configuration."""
        return {
            "communication": {
                "pattern": "hub_and_spoke",
                "description": "Supervisor communicates with all workers directly",
                "supervisor_to_workers": "direct",
                "worker_to_worker": "via_supervisor",
                "broadcast_enabled": False,
                "message_logging": True
            },
            
            "task_distribution": {
                "strategy": "intelligent_routing",
                "load_balancing": True,
                "capability_matching": True,
                "workload_consideration": True,
                "performance_based": False
            },
            
            "error_handling": {
                "retry_failed_tasks": True,
                "max_retry_attempts": 2,
                "fallback_to_supervisor": True,
                "escalation_threshold": 3
            },
            
            "monitoring": {
                "track_performance": True,
                "log_interactions": True,
                "measure_response_times": True,
                "capability_utilization": True
            }
        }
    
    def _generate_runtime_config(self) -> Dict[str, Any]:
        """Generate runtime configuration."""
        return {
            "execution": {
                "max_concurrent_tasks": 5,
                "task_timeout_seconds": 300,
                "supervisor_timeout_seconds": 30,
                "worker_timeout_seconds": 120
            },
            
            "resources": {
                "memory_limit_mb": 2048,
                "cpu_limit_percent": 80,
                "max_context_length": 8000
            },
            
            "logging": {
                "enabled": True,
                "level": "INFO",
                "format": "structured",
                "include_traces": True,
                "log_worker_outputs": True
            },
            
            "debugging": {
                "debug_mode": False,
                "verbose_logging": False,
                "step_by_step_execution": False,
                "save_intermediate_results": False
            }
        }
    
    def _generate_deployment_config(self, team_name: str) -> Dict[str, Any]:
        """Generate deployment configuration."""
        safe_name = "".join(c for c in team_name if c.isalnum() or c in ('_', '-')).lower()
        
        return {
            "environment": {
                "name": f"{safe_name}_hierarchical_team",
                "type": "simple_hierarchical",
                "auto_scaling": False,
                "health_checks": True
            },
            
            "api": {
                "enabled": True,
                "host": "localhost",
                "port": 8000,
                "endpoints": {
                    "chat": "/chat",
                    "status": "/status",
                    "metrics": "/metrics",
                    "health": "/health"
                }
            },
            
            "security": {
                "authentication": False,
                "rate_limiting": True,
                "max_requests_per_minute": 60,
                "input_validation": True
            },
            
            "persistence": {
                "save_conversations": True,
                "save_team_state": True,
                "backup_frequency": "hourly",
                "retention_days": 30
            }
        }
    
    def _generate_supervisor_prompt_template(self, supervisor_metadata) -> str:
        """Generate supervisor prompt template."""
        capabilities_list = ', '.join([cap.value for cap in supervisor_metadata.capabilities])
        
        return f"""You are {supervisor_metadata.name}, a supervisor agent managing a team of specialized workers.

Your Role:
- Analyze incoming user requests
- Route tasks to the most suitable worker based on their capabilities
- Coordinate between workers when needed
- Provide final responses to users
- Monitor team performance and workflow

Your Capabilities: {capabilities_list}

Available Workers and their specializations: {{worker_capabilities}}

Guidelines:
1. Always analyze the user request to understand what type of task it is
2. Match tasks to workers based on their capabilities and specializations
3. If a task requires multiple workers, coordinate the workflow
4. If no worker is suitable, handle the task yourself if possible
5. Always provide clear, helpful responses to users
6. Learn from past interactions to improve routing decisions

Current Context: {{task_context}}
Previous Interactions: {{memory_context}}

User Request: {{user_input}}

Analyze this request and either:
1. Route it to the appropriate worker with clear instructions
2. Handle it yourself if you're best suited
3. Ask for clarification if the request is ambiguous"""
    
    def _generate_routing_prompt_template(self) -> str:
        """Generate routing decision prompt template."""
        return """Analyze the user request and decide which worker should handle it.

User Request: {user_request}

Available Workers:
{available_workers}

Worker Specializations:
{worker_specializations}

Consider:
1. Which worker's capabilities best match the request?
2. Which worker's specializations are most relevant?
3. Are there any workers currently overloaded?
4. Does this task require specific tools or knowledge?

Provide your routing decision with reasoning."""
    
    def _extract_llm_config(self, config_file_path: str) -> Dict[str, Any]:
        """Extract LLM configuration from agent config file."""
        try:
            with open(config_file_path, 'r') as f:
                agent_config = yaml.safe_load(f)
            
            llm_config = agent_config.get('llm', {})
            return {
                "provider": llm_config.get('provider', 'openai'),
                "model": llm_config.get('model', 'gpt-4o-mini'),
                "temperature": llm_config.get('temperature', 0.7),
                "max_tokens": llm_config.get('max_tokens', 2000),
                "api_key_env": llm_config.get('api_key_env', 'OPENAI_API_KEY')
            }
        except Exception:
            # Return default configuration
            return {
                "provider": "openai",
                "model": "gpt-4o-mini", 
                "temperature": 0.7,
                "max_tokens": 2000,
                "api_key_env": "OPENAI_API_KEY"
            }
    
    def validate_simple_config(self, supervisor_id: str, worker_ids: List[str]) -> Dict[str, Any]:
        """Validate a simple hierarchical team configuration."""
        validation = {
            "valid": True,
            "errors": [],
            "warnings": [],
            "suggestions": []
        }
        
        # Validate supervisor
        if supervisor_id not in self.agent_library.agents:
            validation["errors"].append(f"Supervisor '{supervisor_id}' not found")
            validation["valid"] = False
        else:
            supervisor_metadata = self.agent_library.agents[supervisor_id]
            if not supervisor_metadata.can_supervise:
                validation["warnings"].append(f"'{supervisor_metadata.name}' may not be optimal as supervisor")
        
        # Validate workers
        if not worker_ids:
            validation["errors"].append("No workers specified")
            validation["valid"] = False
        else:
            for worker_id in worker_ids:
                if worker_id not in self.agent_library.agents:
                    validation["errors"].append(f"Worker '{worker_id}' not found")
                    validation["valid"] = False
        
        # Check team size
        if len(worker_ids) == 1:
            validation["warnings"].append("Single worker teams may not need supervision")
        elif len(worker_ids) > 10:
            validation["warnings"].append("Large teams may be harder to coordinate")
        
        # Check capability coverage
        all_capabilities = set()
        if supervisor_id in self.agent_library.agents:
            supervisor_metadata = self.agent_library.agents[supervisor_id]
            all_capabilities.update([cap.value for cap in supervisor_metadata.capabilities])
        
        for worker_id in worker_ids:
            if worker_id in self.agent_library.agents:
                worker_metadata = self.agent_library.agents[worker_id]
                all_capabilities.update([cap.value for cap in worker_metadata.capabilities])
        
        essential_capabilities = {"web_search", "writing", "research"}
        missing_capabilities = essential_capabilities - all_capabilities
        
        if missing_capabilities:
            validation["suggestions"].append(
                f"Consider adding workers with: {', '.join(missing_capabilities)}"
            )
        
        return validation
    
    def save_simple_config(self, config_yaml: str, team_name: str, output_dir: str = "configs/simple_teams") -> str:
        """Save the simple configuration to a file."""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # Generate filename
        safe_name = "".join(c for c in team_name if c.isalnum() or c in (' ', '_')).rstrip()
        filename = f"{safe_name.replace(' ', '_').lower()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.yml"
        
        file_path = output_path / filename
        
        with open(file_path, 'w') as f:
            f.write(config_yaml)
        
        return str(file_path)
    
    def generate_deployment_script(self, config_yaml: str, team_name: str) -> str:
        """Generate a deployment script for the team."""
        safe_name = "".join(c for c in team_name if c.isalnum() or c in ('_', '-')).lower()
        
        script = f"""#!/usr/bin/env python3
\"\"\"
Deployment script for {team_name}
Generated by Simple Team Builder
\"\"\"
import sys
import os
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.hierarchical.hierarchical_agent import HierarchicalAgentTeam
from src.core.hierarchical_config_loader import HierarchicalConfigLoader

def deploy_{safe_name}():
    \"\"\"Deploy the {team_name} hierarchical team.\"\"\"
    
    # Load configuration
    config_file = Path(__file__).parent / "{safe_name}_team.yml"
    
    if not config_file.exists():
        print(f"âŒ Configuration file not found: {{config_file}}")
        return False
    
    try:
        # Load hierarchical configuration
        loader = HierarchicalConfigLoader()
        config = loader.load_config(str(config_file))
        
        # Create team instance
        team = HierarchicalAgentTeam(
            name="{team_name}",
            hierarchical_config=config.model_dump()
        )
        
        print(f"âœ… {team_name} deployed successfully!")
        print(f"ğŸ“Š Team Info: {{team.get_hierarchy_info()}}")
        
        return team
        
    except Exception as e:
        print(f"âŒ Deployment failed: {{e}}")
        return False

def test_{safe_name}(team, test_message: str = "Hello, team!"):
    \"\"\"Test the deployed team.\"\"\"
    try:
        print(f"ğŸ§ª Testing team with message: '{{test_message}}'")
        result = team.run(test_message)
        print(f"ğŸ“‹ Team Response: {{result.get('response', 'No response')}}")
        return result
    except Exception as e:
        print(f"âŒ Test failed: {{e}}")
        return None

if __name__ == "__main__":
    # Deploy the team
    team = deploy_{safe_name}()
    
    if team:
        # Interactive testing
        print("\\nğŸ’¬ Interactive Testing Mode")
        print("Type 'quit' to exit")
        
        while True:
            user_input = input("\\nEnter test message: ").strip()
            if user_input.lower() in ['quit', 'exit', 'q']:
                break
            
            if user_input:
                test_{safe_name}(team, user_input)
            
        print("ğŸ‘‹ Goodbye!")
    else:
        print("âŒ Deployment failed. Please check your configuration.")
        sys.exit(1)
"""
        
        return script